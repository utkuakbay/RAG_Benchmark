# requirements.txt
# streamlit
# pandas
# langchain
# langchain-google-genai
# langchain-openai
# langchain-community
# faiss-cpu
# sentence-transformers
# python-dotenv

import streamlit as st
import pandas as pd
import time
import os
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field
from dotenv import load_dotenv

# LangChain imports
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_openai import ChatOpenAI

# Load environment variables
load_dotenv()


@dataclass
class ModelMetrics:
    """Model performans metriklerini tutan veri sÄ±nÄ±fÄ±."""
    model_name: str
    response: str
    duration: float
    input_tokens: int
    output_tokens: int
    total_tokens: int
    estimated_cost: float
    retrieved_docs: int


@dataclass
class TestStatistics:
    """Test istatistiklerini tutan veri sÄ±nÄ±fÄ±."""
    total_questions: int = 0
    total_duration: float = 0.0
    model_metrics: Dict[str, List[ModelMetrics]] = field(default_factory=dict)
    
    def add_metric(self, metric: ModelMetrics):
        """Metrik ekle."""
        if metric.model_name not in self.model_metrics:
            self.model_metrics[metric.model_name] = []
        self.model_metrics[metric.model_name].append(metric)
    
    def get_average_duration(self, model_name: str) -> float:
        """Ortalama yanÄ±t sÃ¼resini hesapla."""
        if model_name not in self.model_metrics:
            return 0.0
        metrics = self.model_metrics[model_name]
        return sum(m.duration for m in metrics) / len(metrics) if metrics else 0.0
    
    def get_total_tokens(self, model_name: str) -> int:
        """Toplam token kullanÄ±mÄ±nÄ± hesapla."""
        if model_name not in self.model_metrics:
            return 0
        metrics = self.model_metrics[model_name]
        return sum(m.total_tokens for m in metrics)
    
    def get_total_cost(self, model_name: str) -> float:
        """Toplam maliyeti hesapla."""
        if model_name not in self.model_metrics:
            return 0.0
        metrics = self.model_metrics[model_name]
        return sum(m.estimated_cost for m in metrics)


class CSVProcessor:
    """CSV dosyalarÄ±nÄ± dinamik olarak okuyup chunking iÅŸlemi yapan sÄ±nÄ±f."""
    
    def __init__(self, chunk_size: int = 1000, chunk_overlap: int = 200):
        """
        Args:
            chunk_size: Chunk boyutu
            chunk_overlap: Chunk'lar arasÄ± Ã¶rtÃ¼ÅŸme miktarÄ±
        """
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            length_function=len,
        )
    
    def load_and_chunk(self, uploaded_file) -> List[Document]:
        """
        CSV dosyasÄ±nÄ± yÃ¼kler, her satÄ±rÄ± dinamik olarak iÅŸler ve chunk'lara bÃ¶ler.
        
        Args:
            uploaded_file: Streamlit tarafÄ±ndan yÃ¼klenen dosya
            
        Returns:
            Document listesi (chunk'lanmÄ±ÅŸ)
        """
        try:
            # CSV'yi oku
            df = pd.read_csv(uploaded_file)
            print(f"\n{'='*60}")
            print(f"CSV YÃœKLENDÄ°")
            print(f"{'='*60}")
            print(f"Toplam SatÄ±r SayÄ±sÄ±: {len(df)}")
            print(f"SÃ¼tunlar: {', '.join(df.columns.tolist())}")
            print(f"{'='*60}\n")
            
            # Her satÄ±rÄ± dinamik olarak metne dÃ¶nÃ¼ÅŸtÃ¼r
            documents = []
            for idx, row in df.iterrows():
                # Dinamik olarak tÃ¼m sÃ¼tunlarÄ± birleÅŸtir
                row_text_parts = []
                for column in df.columns:
                    value = row[column]
                    # NaN deÄŸerleri atla
                    if pd.notna(value):
                        row_text_parts.append(f"{column}: {value}")
                
                # SatÄ±r metnini oluÅŸtur
                row_text = " | ".join(row_text_parts)
                
                # Document objesi oluÅŸtur
                doc = Document(
                    page_content=row_text,
                    metadata={"row_index": idx, "source": "corpus.csv"}
                )
                documents.append(doc)
            
            print(f"Chunk Ã¶ncesi dokÃ¼man sayÄ±sÄ±: {len(documents)}")
            
            # Chunk iÅŸlemi uygula
            chunked_documents = self.text_splitter.split_documents(documents)
            
            print(f"Chunk sonrasÄ± dokÃ¼man sayÄ±sÄ±: {len(chunked_documents)}")
            print(f"Ortalama chunk uzunluÄŸu: {sum(len(doc.page_content) for doc in chunked_documents) / len(chunked_documents):.0f} karakter\n")
            
            return chunked_documents
            
        except Exception as e:
            raise Exception(f"CSV iÅŸleme hatasÄ±: {str(e)}")


class RAGPipeline:
    """FAISS vektÃ¶r veritabanÄ± ve retriever yÃ¶netimi yapan sÄ±nÄ±f."""
    
    def __init__(self, documents: List[Document], embedding_model_name: str = "sentence-transformers/all-MiniLM-L6-v2"):
        """
        Args:
            documents: Chunk'lanmÄ±ÅŸ dokÃ¼man listesi
            embedding_model_name: KullanÄ±lacak embedding modeli
        """
        self.documents = documents
        self.embedding_model_name = embedding_model_name
        self.embeddings = None
        self.vectorstore = None
        self._initialize_vectorstore()
    
    def _initialize_vectorstore(self):
        """VektÃ¶r veritabanÄ±nÄ± baÅŸlatÄ±r."""
        try:
            print(f"{'='*60}")
            print(f"VEKTÃ–R VERÄ°TABANI OLUÅTURULUYOR")
            print(f"{'='*60}")
            print(f"Embedding Model: {self.embedding_model_name}")
            
            # Embedding modeli oluÅŸtur
            self.embeddings = HuggingFaceEmbeddings(
                model_name=self.embedding_model_name,
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )
            
            # FAISS vektÃ¶r veritabanÄ± oluÅŸtur
            start_time = time.time()
            self.vectorstore = FAISS.from_documents(
                documents=self.documents,
                embedding=self.embeddings
            )
            elapsed_time = time.time() - start_time
            
            print(f"VektÃ¶r veritabanÄ± oluÅŸturuldu ({elapsed_time:.2f} saniye)")
            print(f"Ä°ndekslenen dokÃ¼man sayÄ±sÄ±: {len(self.documents)}")
            print(f"{'='*60}\n")
            
        except Exception as e:
            raise Exception(f"VektÃ¶r veritabanÄ± oluÅŸturma hatasÄ±: {str(e)}")
    
    def get_retriever(self, k: int = 3):
        """
        Retriever objesi dÃ¶ndÃ¼rÃ¼r.
        
        Args:
            k: En alakalÄ± k dokÃ¼manÄ± getir
            
        Returns:
            Retriever objesi
        """
        if self.vectorstore is None:
            raise Exception("VektÃ¶r veritabanÄ± henÃ¼z oluÅŸturulmamÄ±ÅŸ!")
        
        return self.vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": k}
        )


class ModelManager:
    """LLM modellerini yÃ¶neten sÄ±nÄ±f."""
    
    # Model fiyatlandÄ±rmasÄ± (USD per 1M tokens - GÃ¼ncel fiyatlar)
    PRICING = {
        "Gemini": {
            "input": 0.075 / 1_000_000,  # $0.075 per 1M input tokens
            "output": 0.30 / 1_000_000,  # $0.30 per 1M output tokens
        },
        "GPT": {
            "input": 0.50 / 1_000_000,  # GPT-3.5-turbo: $0.50 per 1M input tokens
            "output": 1.50 / 1_000_000,  # GPT-3.5-turbo: $1.50 per 1M output tokens
        }
    }
    
    @staticmethod
    def get_models(gemini_api_key: Optional[str] = None, 
                   openai_api_key: Optional[str] = None) -> Dict[str, Any]:
        """
        Model sÃ¶zlÃ¼ÄŸÃ¼ oluÅŸturur.
        
        Args:
            gemini_api_key: Google Gemini API key
            openai_api_key: OpenAI API key
            
        Returns:
            Model ismi -> Model objesi sÃ¶zlÃ¼ÄŸÃ¼
        """
        models = {}
        
        try:
            if gemini_api_key:
                print(f"{'='*60}")
                print(f"MODELLER YÃœKLENÄ°YOR")
                print(f"{'='*60}")
                
                # Gemini modelini yÃ¼kle
                gemini_model = ChatGoogleGenerativeAI(
                    model="gemini-2.5-flash",
                    google_api_key=gemini_api_key,
                    temperature=0.0
                )
                models["Gemini"] = gemini_model
                print(f"âœ“ Gemini model yÃ¼klendi")
            else:
                print(f"âš  Gemini API key bulunamadÄ±, atlanÄ±yor...")
            
            if openai_api_key:
                # OpenAI modelini yÃ¼kle
                openai_model = ChatOpenAI(
                    model="gpt-3.5-turbo",
                    openai_api_key=openai_api_key,
                    temperature=0.0
                )
                models["GPT"] = openai_model
                print(f"âœ“ GPT model yÃ¼klendi")
            else:
                print(f"âš  OpenAI API key bulunamadÄ±, atlanÄ±yor...")
            
            print(f"{'='*60}\n")
            
            if not models:
                raise Exception("HiÃ§bir model yÃ¼klenemedi! En az bir geÃ§erli API key gerekli.")
            
            return models
            
        except Exception as e:
            raise Exception(f"Model yÃ¼kleme hatasÄ±: {str(e)}")
    
    @staticmethod
    def calculate_cost(model_name: str, input_tokens: int, output_tokens: int) -> float:
        """
        Tahmini maliyeti hesaplar.
        
        Args:
            model_name: Model adÄ±
            input_tokens: Input token sayÄ±sÄ±
            output_tokens: Output token sayÄ±sÄ±
            
        Returns:
            Tahmini maliyet (USD)
        """
        if model_name not in ModelManager.PRICING:
            return 0.0
        
        pricing = ModelManager.PRICING[model_name]
        cost = (input_tokens * pricing["input"]) + (output_tokens * pricing["output"])
        return cost


class BenchmarkRunner:
    """Test Ã§alÄ±ÅŸtÄ±rma ve detaylÄ± loglama yapan sÄ±nÄ±f."""
    
    def __init__(self):
        """BenchmarkRunner baÅŸlatÄ±cÄ±."""
        self.statistics = TestStatistics()
        self.prompt_template = ChatPromptTemplate.from_template(
            """AÅŸaÄŸÄ±daki baÄŸlamÄ± kullanarak soruyu cevapla. 
Bilgi baÄŸlamda yoksa 'Bilgi bulunamadÄ±' de.

BaÄŸlam: {context}

Soru: {question}"""
        )
    
    def _estimate_tokens(self, text: str) -> int:
        """
        Basit token tahmini (yaklaÅŸÄ±k 4 karakter = 1 token).
        
        Args:
            text: Token sayÄ±sÄ± tahmin edilecek metin
            
        Returns:
            Tahmini token sayÄ±sÄ±
        """
        return len(text) // 4
    
    def _run_single_query(self, 
                         question: str, 
                         model_name: str, 
                         model: Any, 
                         retriever: Any) -> ModelMetrics:
        """
        Tek bir soru iÃ§in model Ã§alÄ±ÅŸtÄ±rÄ±r ve metrikleri toplar.
        
        Args:
            question: Soru
            model_name: Model adÄ±
            model: Model objesi
            retriever: Retriever objesi
            
        Returns:
            ModelMetrics objesi
        """
        # Manuel RAG chain oluÅŸtur (LangChain 1.0 uyumlu)
        def format_docs(docs):
            return "\n\n".join(doc.page_content for doc in docs)
        
        # Chain: Retriever -> Format -> Prompt -> LLM -> Parse
        rag_chain = (
            {"context": retriever | format_docs, "question": RunnablePassthrough()}
            | self.prompt_template
            | model
            | StrOutputParser()
        )
        
        # Sorguyu Ã§alÄ±ÅŸtÄ±r ve sÃ¼reyi Ã¶lÃ§
        start_time = time.time()
        
        try:
            # DokÃ¼manlarÄ± al (metrik iÃ§in)
            retrieved_docs = retriever.invoke(question)
            
            # RAG chain'i Ã§alÄ±ÅŸtÄ±r
            response = rag_chain.invoke(question)
            
            duration = time.time() - start_time
            
            # Token hesaplama
            context_text = "\n\n".join([doc.page_content for doc in retrieved_docs])
            input_text = f"{context_text}\n{question}"
            
            input_tokens = self._estimate_tokens(input_text)
            output_tokens = self._estimate_tokens(response)
            total_tokens = input_tokens + output_tokens
            
            # Maliyeti hesapla
            estimated_cost = ModelManager.calculate_cost(
                model_name, 
                input_tokens, 
                output_tokens
            )
            
            # Metrik objesi oluÅŸtur
            metrics = ModelMetrics(
                model_name=model_name,
                response=response,
                duration=duration,
                input_tokens=input_tokens,
                output_tokens=output_tokens,
                total_tokens=total_tokens,
                estimated_cost=estimated_cost,
                retrieved_docs=len(retrieved_docs)
            )
            
            return metrics
            
        except Exception as e:
            # Hata durumunda boÅŸ metrik dÃ¶ndÃ¼r
            duration = time.time() - start_time
            return ModelMetrics(
                model_name=model_name,
                response=f"HATA: {str(e)}",
                duration=duration,
                input_tokens=0,
                output_tokens=0,
                total_tokens=0,
                estimated_cost=0.0,
                retrieved_docs=0
            )
    
    def _print_question_header(self, question_num: int, total_questions: int, 
                              question: str, ideal_answer: str):
        """Soru baÅŸlÄ±ÄŸÄ±nÄ± yazdÄ±rÄ±r."""
        print(f"\n{'='*80}")
        print(f"SORU {question_num}/{total_questions}: {question}")
        print(f"Ä°DEAL CEVAP: {ideal_answer}")
        print(f"{'='*80}\n")
    
    def _print_model_results(self, metrics: ModelMetrics):
        """Model sonuÃ§larÄ±nÄ± yazdÄ±rÄ±r."""
        print(f"--- MODEL: {metrics.model_name} ---")
        print(f"CEVAP: {metrics.response}")
        print(f"SÃœRE: {metrics.duration:.2f} saniye")
        print(f"TOKEN KULLANIMI:")
        print(f"  â€¢ Input Tokens: {metrics.input_tokens}")
        print(f"  â€¢ Output Tokens: {metrics.output_tokens}")
        print(f"  â€¢ Toplam: {metrics.total_tokens} tokens")
        print(f"TAHMÄ°NÄ° MALÄ°YET: ${metrics.estimated_cost:.6f}")
        print(f"RETRIEVE EDÄ°LEN DOKÃœMAN: {metrics.retrieved_docs} adet\n")
    
    def _print_summary(self):
        """Test Ã¶zet istatistiklerini yazdÄ±rÄ±r."""
        print(f"\n{'='*80}")
        print(f"â•”{'='*78}â•—")
        print(f"â•‘{' '*24}TEST TAMAMLANDI - Ã–ZET{' '*31}â•‘")
        print(f"â•š{'='*78}â•")
        print(f"\nGENEL BÄ°LGÄ°LER:")
        print(f"  â€¢ Toplam Soru SayÄ±sÄ±: {self.statistics.total_questions}")
        print(f"  â€¢ Toplam Test SÃ¼resi: {self.statistics.total_duration:.2f} saniye")
        
        for model_name in self.statistics.model_metrics.keys():
            avg_duration = self.statistics.get_average_duration(model_name)
            total_tokens = self.statistics.get_total_tokens(model_name)
            total_cost = self.statistics.get_total_cost(model_name)
            
            print(f"\n{model_name.upper()} PERFORMANSI:")
            print(f"  â€¢ Ortalama YanÄ±t SÃ¼resi: {avg_duration:.2f} saniye")
            print(f"  â€¢ Toplam Token KullanÄ±mÄ±: {total_tokens}")
            print(f"  â€¢ Tahmini Toplam Maliyet: ${total_cost:.6f}")
        
        print(f"{'='*80}\n")
    
    def run_test(self, 
                 test_df: pd.DataFrame, 
                 retriever: Any, 
                 models: Dict[str, Any]) -> TestStatistics:
        """
        Test setini Ã§alÄ±ÅŸtÄ±rÄ±r ve detaylÄ± loglar.
        
        Args:
            test_df: Test DataFrame (soru, ideal_cevap sÃ¼tunlarÄ±)
            retriever: Retriever objesi
            models: Model sÃ¶zlÃ¼ÄŸÃ¼
            
        Returns:
            TestStatistics objesi
        """
        try:
            # SÃ¼tun kontrolÃ¼
            required_columns = ["soru", "ideal_cevap"]
            for col in required_columns:
                if col not in test_df.columns:
                    raise Exception(f"Test CSV'sinde '{col}' sÃ¼tunu bulunamadÄ±!")
            
            print(f"\n{'='*80}")
            print(f"TEST BAÅLIYOR")
            print(f"{'='*80}")
            print(f"Toplam Soru SayÄ±sÄ±: {len(test_df)}")
            print(f"Test Edilecek Modeller: {', '.join(models.keys())}")
            print(f"{'='*80}\n")
            
            self.statistics.total_questions = len(test_df)
            test_start_time = time.time()
            
            # Her soru iÃ§in dÃ¶ngÃ¼
            for idx, row in test_df.iterrows():
                question = row["soru"]
                ideal_answer = row["ideal_cevap"]
                
                # Soru baÅŸlÄ±ÄŸÄ±nÄ± yazdÄ±r
                self._print_question_header(
                    idx + 1, 
                    len(test_df), 
                    question, 
                    ideal_answer
                )
                
                # Her model iÃ§in test Ã§alÄ±ÅŸtÄ±r
                for model_name, model in models.items():
                    metrics = self._run_single_query(
                        question=question,
                        model_name=model_name,
                        model=model,
                        retriever=retriever
                    )
                    
                    # MetriÄŸi kaydet
                    self.statistics.add_metric(metrics)
                    
                    # SonuÃ§larÄ± yazdÄ±r
                    self._print_model_results(metrics)
            
            # Toplam sÃ¼reyi hesapla
            self.statistics.total_duration = time.time() - test_start_time
            
            # Ã–zet istatistikleri yazdÄ±r
            self._print_summary()
            
            return self.statistics
            
        except Exception as e:
            raise Exception(f"Test Ã§alÄ±ÅŸtÄ±rma hatasÄ±: {str(e)}")


def main():
    """Ana Streamlit uygulamasÄ±."""
    
    # Sayfa yapÄ±landÄ±rmasÄ±
    st.set_page_config(
        page_title="RAG Benchmark V1",
        page_icon="ğŸ“Š",
        layout="wide"
    )
    
    # BaÅŸlÄ±k
    st.title("Dinamik CSV RAG Benchmark (V1)")
    st.markdown("""
    Bu uygulama, **Google Gemini** ve **OpenAI GPT** modellerinin RAG performansÄ±nÄ± 
    dinamik CSV korpusu Ã¼zerinde karÅŸÄ±laÅŸtÄ±rmanÄ±za olanak saÄŸlar.
    """)
    
    # Sidebar - API Keys
    st.sidebar.header("ğŸ”‘ API AnahtarlarÄ±")
    st.sidebar.markdown("API anahtarlarÄ±nÄ±zÄ± girin veya .env dosyasÄ±ndan yÃ¼klensin.")
    
    # .env'den yÃ¼kle veya input al
    default_gemini_key = os.getenv("GOOGLE_API_KEY", "")
    default_openai_key = os.getenv("OPENAI_API_KEY", "")
    
    gemini_api_key = st.sidebar.text_input(
        "Google Gemini API Key",
        value=default_gemini_key,
        type="password",
        help="Gemini API anahtarÄ±nÄ±zÄ± girin"
    )
    
    openai_api_key = st.sidebar.text_input(
        "OpenAI API Key",
        value=default_openai_key,
        type="password",
        help="OpenAI API anahtarÄ±nÄ±zÄ± girin"
    )
    
    # Ayarlar
    st.sidebar.header("âš™ï¸ Ayarlar")
    chunk_size = st.sidebar.slider("Chunk Size", 500, 2000, 1000, 100)
    chunk_overlap = st.sidebar.slider("Chunk Overlap", 0, 500, 200, 50)
    retriever_k = st.sidebar.slider("Retriever K", 1, 10, 3, 1)
    
    # Dosya yÃ¼kleyiciler
    st.header("ğŸ“ Dosya YÃ¼kleme")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("1. Corpus CSV")
        corpus_file = st.file_uploader(
            "KÃ¼tÃ¼phane/Corpus CSV dosyasÄ±nÄ± yÃ¼kleyin",
            type=["csv"],
            key="corpus",
            help="Dinamik yapÄ±da herhangi bir CSV dosyasÄ± yÃ¼kleyebilirsiniz"
        )
        if corpus_file:
            st.success(f"âœ“ {corpus_file.name} yÃ¼klendi")
    
    with col2:
        st.subheader("2. Test CSV")
        test_file = st.file_uploader(
            "Test sorularÄ± CSV dosyasÄ±nÄ± yÃ¼kleyin",
            type=["csv"],
            key="test",
            help="'soru' ve 'ideal_cevap' sÃ¼tunlarÄ± zorunludur"
        )
        if test_file:
            st.success(f"âœ“ {test_file.name} yÃ¼klendi")
    
    # Test baÅŸlatma butonu
    st.header("ğŸš€ Test")
    
    if st.button("Testi BaÅŸlat", type="primary", use_container_width=True):
        # Validasyonlar
        if not corpus_file:
            st.error("âŒ LÃ¼tfen corpus CSV dosyasÄ± yÃ¼kleyin!")
            return
        
        if not test_file:
            st.error("âŒ LÃ¼tfen test CSV dosyasÄ± yÃ¼kleyin!")
            return
        
        if not gemini_api_key and not openai_api_key:
            st.error("âŒ En az bir API key gerekli!")
            return
        
        try:
            # Ä°ÅŸlem adÄ±mlarÄ±
            with st.spinner("ğŸ“„ Corpus iÅŸleniyor..."):
                # CSV Processor
                csv_processor = CSVProcessor(
                    chunk_size=chunk_size,
                    chunk_overlap=chunk_overlap
                )
                documents = csv_processor.load_and_chunk(corpus_file)
                st.info(f"âœ“ {len(documents)} chunk oluÅŸturuldu")
            
            with st.spinner("ğŸ” VektÃ¶r veritabanÄ± oluÅŸturuluyor..."):
                # RAG Pipeline
                rag_pipeline = RAGPipeline(documents)
                retriever = rag_pipeline.get_retriever(k=retriever_k)
                st.info(f"âœ“ VektÃ¶r veritabanÄ± hazÄ±r")
            
            with st.spinner("ğŸ¤– Modeller yÃ¼kleniyor..."):
                # Model Manager
                models = ModelManager.get_models(
                    gemini_api_key=gemini_api_key if gemini_api_key else None,
                    openai_api_key=openai_api_key if openai_api_key else None
                )
                st.info(f"âœ“ {len(models)} model yÃ¼klendi: {', '.join(models.keys())}")
            
            with st.spinner("ğŸ§ª Test Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor... (Konsol Ã§Ä±ktÄ±larÄ±nÄ± kontrol edin)"):
                # Test CSV'yi oku
                test_df = pd.read_csv(test_file)
                
                # Benchmark Runner
                benchmark_runner = BenchmarkRunner()
                statistics = benchmark_runner.run_test(
                    test_df=test_df,
                    retriever=retriever,
                    models=models
                )
            
            # BaÅŸarÄ± mesajÄ±
            st.success("âœ… Test baÅŸarÄ±yla tamamlandÄ±!")
            st.balloons()
            
            # Ã–zet bilgileri gÃ¶ster
            st.header("ğŸ“ˆ Test Ã–zeti")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Toplam Soru", statistics.total_questions)
            with col2:
                st.metric("Toplam SÃ¼re", f"{statistics.total_duration:.2f}s")
            with col3:
                st.metric("Test Edilen Model", len(models))
            
            # Model bazlÄ± metrikler
            for model_name in statistics.model_metrics.keys():
                st.subheader(f"ğŸ¤– {model_name} Metrikleri")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    avg_duration = statistics.get_average_duration(model_name)
                    st.metric("Ort. YanÄ±t SÃ¼resi", f"{avg_duration:.2f}s")
                with col2:
                    total_tokens = statistics.get_total_tokens(model_name)
                    st.metric("Toplam Token", f"{total_tokens:,}")
                with col3:
                    total_cost = statistics.get_total_cost(model_name)
                    st.metric("Tahmini Maliyet", f"${total_cost:.6f}")
            
            st.info("ğŸ’¡ DetaylÄ± loglar iÃ§in konsol Ã§Ä±ktÄ±larÄ±nÄ± kontrol edin!")
            
        except Exception as e:
            st.error(f"âŒ Hata oluÅŸtu: {str(e)}")
            import traceback
            st.code(traceback.format_exc())


if __name__ == "__main__":
    main()

